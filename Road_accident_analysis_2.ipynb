{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11641ff",
   "metadata": {},
   "source": [
    "# Data  Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12334ad9",
   "metadata": {},
   "source": [
    "The code starts with the cell which imports the required libraries and also used Python function. This function utilizes a library called Pandas to fetch information from three CSV files stored on GitHub and organize it into Pandas DataFrames. Additionally, we apply a setting called `low_memory=False` to the function to prevent any alerts or notifications regarding the presence of mixed data types within the columns. This setting is especially useful when handling extensive datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3a0d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.exceptions import UndefinedMetricWarning \n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "#data on github url\n",
    "url_accident = \"https://raw.githubusercontent.com/Sayalinale/RoadTraffic-Analysis/main/dft-road-casualty-statistics-accident-2021.csv\"\n",
    "url_casualty = \"https://raw.githubusercontent.com/Sayalinale/RoadTraffic-Analysis/main/dft-road-casualty-statistics-casualty-2021.csv\"\n",
    "url_vehicle = \"https://raw.githubusercontent.com/Sayalinale/RoadTraffic-Analysis/main/dft-road-casualty-statistics-vehicle-2021.csv\"\n",
    "\n",
    "# Load CSV files into Pandas  DataFrames with low_memory=False\n",
    "df_accident_data = pd.read_csv(url_accident, low_memory=False)\n",
    "df_casualty_data = pd.read_csv(url_casualty, low_memory=False)\n",
    "df_vehicle_data = pd.read_csv(url_vehicle, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5175dfe",
   "metadata": {},
   "source": [
    "To know more about the size of the dataset checked the shape three csv files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de00514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101087, 36)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accident_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8606a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128209, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_casualty_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dab9e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186443, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vehicle_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62be1488",
   "metadata": {},
   "source": [
    "As we got the output from the above cell we got the how many records and attributes are there in three different files now merging of three files would be helpful to work with the dataset. We are going to merge three files using the common column in three files which is 'accident_reference'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3d4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the 'accident_reference' column\n",
    "merged_data = pd.merge(df_accident_data, df_casualty_data, on='accident_reference')\n",
    "merged_data = pd.merge(merged_data, df_vehicle_data, on='accident_reference')\n",
    "\n",
    "# Now, 'merged_data' contains the merged data from all three DataFrames based on 'accident_reference'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec29889",
   "metadata": {},
   "source": [
    "To know about the merged files. I have printed out the shape and column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1272bdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accident_index_x', 'accident_year_x', 'accident_reference',\n",
      "       'location_easting_osgr', 'location_northing_osgr', 'longitude',\n",
      "       'latitude', 'police_force', 'accident_severity', 'number_of_vehicles',\n",
      "       'number_of_casualties', 'date', 'day_of_week', 'time',\n",
      "       'local_authority_district', 'local_authority_ons_district',\n",
      "       'local_authority_highway', 'first_road_class', 'first_road_number',\n",
      "       'road_type', 'speed_limit', 'junction_detail', 'junction_control',\n",
      "       'second_road_class', 'second_road_number',\n",
      "       'pedestrian_crossing_human_control',\n",
      "       'pedestrian_crossing_physical_facilities', 'light_conditions',\n",
      "       'weather_conditions', 'road_surface_conditions',\n",
      "       'special_conditions_at_site', 'carriageway_hazards',\n",
      "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
      "       'trunk_road_flag', 'trunk_road_flag.1', 'accident_index_y',\n",
      "       'accident_year_y', 'vehicle_reference_x', 'casualty_reference',\n",
      "       'casualty_class', 'sex_of_casualty', 'age_of_casualty',\n",
      "       'age_band_of_casualty', 'casualty_severity', 'pedestrian_location',\n",
      "       'pedestrian_movement', 'car_passenger', 'bus_or_coach_passenger',\n",
      "       'pedestrian_road_maintenance_worker', 'casualty_type',\n",
      "       'casualty_home_area_type', 'casualty_imd_decile', 'lsoa_of_casualty',\n",
      "       'accident_index', 'accident_year', 'vehicle_reference_y',\n",
      "       'vehicle_type', 'towing_and_articulation', 'vehicle_manoeuvre',\n",
      "       'vehicle_direction_from', 'vehicle_direction_to',\n",
      "       'vehicle_location_restricted_lane',\n",
      "       'vehicle_location_restricted_lane.1', 'skidding_and_overturning',\n",
      "       'hit_object_in_carriageway', 'vehicle_leaving_carriageway',\n",
      "       'hit_object_off_carriageway', 'first_point_of_impact',\n",
      "       'vehicle_left_hand_drive', 'journey_purpose_of_driver', 'sex_of_driver',\n",
      "       'age_of_driver', 'age_band_of_driver', 'engine_capacity_cc',\n",
      "       'propulsion_code', 'age_of_vehicle', 'generic_make_model',\n",
      "       'driver_imd_decile', 'driver_home_area_type', 'lsoa_of_driver',\n",
      "       'Unnamed: 28'],\n",
      "      dtype='object')\n",
      "(246314, 82)\n"
     ]
    }
   ],
   "source": [
    "print(merged_data.columns)\n",
    "print(merged_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667fbb79",
   "metadata": {},
   "source": [
    "When we merged the three csv files, there are few coulmns which are similar,to confirm it we have checked values from each column. In the below given code's output it shows that accident_index and accident_year has multiple columns of same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a200dcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Columns accident_index_x, accident_index, accident_index_y:\n",
      "All values are the same: True\n",
      "\n",
      "2. Columns accident_year_x, accident_year_y, accident_year:\n",
      "All values are the same: True\n"
     ]
    }
   ],
   "source": [
    "# Check if the columns have the same values\n",
    "# 1. Check columns: accident_index_x, accident_index, accident_index_y\n",
    "same_accident_index = merged_data['accident_index_x'] == merged_data['accident_index_y']\n",
    "same_accident_index = same_accident_index & (merged_data['accident_index_x'] == merged_data['accident_index'])\n",
    "\n",
    "# 2. Check columns: accident_year_x, accident_year_y, accident_year\n",
    "same_accident_year = merged_data['accident_year_x'] == merged_data['accident_year_y']\n",
    "same_accident_year = same_accident_year & (merged_data['accident_year_x'] == merged_data['accident_year'])\n",
    "\n",
    "# Print the results\n",
    "print(\"1. Columns accident_index_x, accident_index, accident_index_y:\")\n",
    "print(\"All values are the same:\", same_accident_index.all())\n",
    "\n",
    "print(\"\\n2. Columns accident_year_x, accident_year_y, accident_year:\")\n",
    "print(\"All values are the same:\", same_accident_year.all())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640d8e5d",
   "metadata": {},
   "source": [
    "In this step we will check null values for the merged file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd081121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'accident_index_x': 0 missing values\n",
      "Column 'accident_year_x': 0 missing values\n",
      "Column 'accident_reference': 0 missing values\n",
      "Column 'location_easting_osgr': 43 missing values\n",
      "Column 'location_northing_osgr': 43 missing values\n",
      "Column 'longitude': 43 missing values\n",
      "Column 'latitude': 43 missing values\n",
      "Column 'police_force': 0 missing values\n",
      "Column 'accident_severity': 0 missing values\n",
      "Column 'number_of_vehicles': 0 missing values\n",
      "Column 'number_of_casualties': 0 missing values\n",
      "Column 'date': 0 missing values\n",
      "Column 'day_of_week': 0 missing values\n",
      "Column 'time': 0 missing values\n",
      "Column 'local_authority_district': 0 missing values\n",
      "Column 'local_authority_ons_district': 0 missing values\n",
      "Column 'local_authority_highway': 0 missing values\n",
      "Column 'first_road_class': 0 missing values\n",
      "Column 'first_road_number': 0 missing values\n",
      "Column 'road_type': 0 missing values\n",
      "Column 'speed_limit': 0 missing values\n",
      "Column 'junction_detail': 0 missing values\n",
      "Column 'junction_control': 0 missing values\n",
      "Column 'second_road_class': 0 missing values\n",
      "Column 'second_road_number': 0 missing values\n",
      "Column 'pedestrian_crossing_human_control': 0 missing values\n",
      "Column 'pedestrian_crossing_physical_facilities': 0 missing values\n",
      "Column 'light_conditions': 0 missing values\n",
      "Column 'weather_conditions': 0 missing values\n",
      "Column 'road_surface_conditions': 0 missing values\n",
      "Column 'special_conditions_at_site': 0 missing values\n",
      "Column 'carriageway_hazards': 0 missing values\n",
      "Column 'urban_or_rural_area': 0 missing values\n",
      "Column 'did_police_officer_attend_scene_of_accident': 0 missing values\n",
      "Column 'trunk_road_flag': 0 missing values\n",
      "Column 'trunk_road_flag.1': 0 missing values\n",
      "Column 'accident_index_y': 0 missing values\n",
      "Column 'accident_year_y': 0 missing values\n",
      "Column 'vehicle_reference_x': 0 missing values\n",
      "Column 'casualty_reference': 0 missing values\n",
      "Column 'casualty_class': 0 missing values\n",
      "Column 'sex_of_casualty': 0 missing values\n",
      "Column 'age_of_casualty': 0 missing values\n",
      "Column 'age_band_of_casualty': 0 missing values\n",
      "Column 'casualty_severity': 0 missing values\n",
      "Column 'pedestrian_location': 0 missing values\n",
      "Column 'pedestrian_movement': 0 missing values\n",
      "Column 'car_passenger': 0 missing values\n",
      "Column 'bus_or_coach_passenger': 0 missing values\n",
      "Column 'pedestrian_road_maintenance_worker': 0 missing values\n",
      "Column 'casualty_type': 0 missing values\n",
      "Column 'casualty_home_area_type': 0 missing values\n",
      "Column 'casualty_imd_decile': 0 missing values\n",
      "Column 'lsoa_of_casualty': 0 missing values\n",
      "Column 'accident_index': 0 missing values\n",
      "Column 'accident_year': 0 missing values\n",
      "Column 'vehicle_reference_y': 0 missing values\n",
      "Column 'vehicle_type': 0 missing values\n",
      "Column 'towing_and_articulation': 0 missing values\n",
      "Column 'vehicle_manoeuvre': 0 missing values\n",
      "Column 'vehicle_direction_from': 0 missing values\n",
      "Column 'vehicle_direction_to': 0 missing values\n",
      "Column 'vehicle_location_restricted_lane': 0 missing values\n",
      "Column 'vehicle_location_restricted_lane.1': 0 missing values\n",
      "Column 'skidding_and_overturning': 0 missing values\n",
      "Column 'hit_object_in_carriageway': 0 missing values\n",
      "Column 'vehicle_leaving_carriageway': 0 missing values\n",
      "Column 'hit_object_off_carriageway': 0 missing values\n",
      "Column 'first_point_of_impact': 0 missing values\n",
      "Column 'vehicle_left_hand_drive': 0 missing values\n",
      "Column 'journey_purpose_of_driver': 0 missing values\n",
      "Column 'sex_of_driver': 0 missing values\n",
      "Column 'age_of_driver': 0 missing values\n",
      "Column 'age_band_of_driver': 0 missing values\n",
      "Column 'engine_capacity_cc': 0 missing values\n",
      "Column 'propulsion_code': 0 missing values\n",
      "Column 'age_of_vehicle': 0 missing values\n",
      "Column 'generic_make_model': 0 missing values\n",
      "Column 'driver_imd_decile': 0 missing values\n",
      "Column 'driver_home_area_type': 0 missing values\n",
      "Column 'lsoa_of_driver': 0 missing values\n",
      "Column 'Unnamed: 28': 246314 missing values\n"
     ]
    }
   ],
   "source": [
    "# Check for null values in the merged DataFrame\n",
    "null_values = merged_data.isnull()\n",
    "\n",
    "# Count the number of null values in each column\n",
    "null_counts = null_values.sum()\n",
    "\n",
    "# Print the null counts for all columns\n",
    "for column, count in null_counts.items():\n",
    "    print(f\"Column '{column}': {count} missing values\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d8070",
   "metadata": {},
   "source": [
    "Now the below cell will remove the null values and the extra columns from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c756d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to keep\n",
    "columns_to_keep = [\n",
    "    'accident_year',\n",
    "    'accident_reference',\n",
    "    'location_easting_osgr',\n",
    "    'location_northing_osgr',\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'police_force',\n",
    "    'accident_severity',\n",
    "    'number_of_vehicles',\n",
    "    'number_of_casualties',\n",
    "    'date',\n",
    "    'day_of_week',\n",
    "    'time',\n",
    "    'local_authority_district',\n",
    "    'first_road_class',\n",
    "    'first_road_number',\n",
    "    'road_type',\n",
    "    'speed_limit',\n",
    "    'junction_detail',\n",
    "    'junction_control',\n",
    "    'second_road_class',\n",
    "    'second_road_number',\n",
    "    'pedestrian_crossing_human_control',\n",
    "    'pedestrian_crossing_physical_facilities',\n",
    "    'light_conditions',\n",
    "    'weather_conditions',\n",
    "    'road_surface_conditions',\n",
    "    'special_conditions_at_site',\n",
    "    'carriageway_hazards',\n",
    "    'urban_or_rural_area',\n",
    "    'did_police_officer_attend_scene_of_accident',\n",
    "    'trunk_road_flag',\n",
    "    'trunk_road_flag.1',\n",
    "    'vehicle_reference_x',\n",
    "    'casualty_reference',\n",
    "    'casualty_class',\n",
    "    'sex_of_casualty',\n",
    "    'age_of_casualty',\n",
    "    'age_band_of_casualty',\n",
    "    'casualty_severity',\n",
    "    'pedestrian_location',\n",
    "    'pedestrian_movement',\n",
    "    'car_passenger',\n",
    "    'bus_or_coach_passenger',\n",
    "    'pedestrian_road_maintenance_worker',\n",
    "    'casualty_type',\n",
    "    'casualty_home_area_type',\n",
    "    'casualty_imd_decile',\n",
    "    'vehicle_type',\n",
    "    'towing_and_articulation',\n",
    "    'vehicle_manoeuvre',\n",
    "    'vehicle_direction_from',\n",
    "    'vehicle_direction_to',\n",
    "    'vehicle_location_restricted_lane',\n",
    "    'vehicle_location_restricted_lane.1',\n",
    "    'skidding_and_overturning',\n",
    "    'hit_object_in_carriageway',\n",
    "    'vehicle_leaving_carriageway',\n",
    "    'hit_object_off_carriageway',\n",
    "    'first_point_of_impact',\n",
    "    'vehicle_left_hand_drive',\n",
    "    'journey_purpose_of_driver',\n",
    "    'sex_of_driver',\n",
    "    'age_of_driver',\n",
    "    'age_band_of_driver',\n",
    "    'engine_capacity_cc',\n",
    "    'propulsion_code',\n",
    "    'age_of_vehicle',\n",
    "    'driver_imd_decile',\n",
    "    'driver_home_area_type',\n",
    "    'lsoa_of_driver'\n",
    "]\n",
    "\n",
    "# Keep only the specified columns\n",
    "merged_data = merged_data[columns_to_keep]\n",
    "\n",
    "# Remove rows with null values\n",
    "merged_data = merged_data.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe74b99",
   "metadata": {},
   "source": [
    "To make sure we have removed the null values and the extra columns the following two cell will print the shape and columns name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fd0573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246271, 71)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2604a38c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['accident_year', 'accident_reference', 'location_easting_osgr',\n",
      "       'location_northing_osgr', 'longitude', 'latitude', 'police_force',\n",
      "       'accident_severity', 'number_of_vehicles', 'number_of_casualties',\n",
      "       'date', 'day_of_week', 'time', 'local_authority_district',\n",
      "       'first_road_class', 'first_road_number', 'road_type', 'speed_limit',\n",
      "       'junction_detail', 'junction_control', 'second_road_class',\n",
      "       'second_road_number', 'pedestrian_crossing_human_control',\n",
      "       'pedestrian_crossing_physical_facilities', 'light_conditions',\n",
      "       'weather_conditions', 'road_surface_conditions',\n",
      "       'special_conditions_at_site', 'carriageway_hazards',\n",
      "       'urban_or_rural_area', 'did_police_officer_attend_scene_of_accident',\n",
      "       'trunk_road_flag', 'trunk_road_flag.1', 'vehicle_reference_x',\n",
      "       'casualty_reference', 'casualty_class', 'sex_of_casualty',\n",
      "       'age_of_casualty', 'age_band_of_casualty', 'casualty_severity',\n",
      "       'pedestrian_location', 'pedestrian_movement', 'car_passenger',\n",
      "       'bus_or_coach_passenger', 'pedestrian_road_maintenance_worker',\n",
      "       'casualty_type', 'casualty_home_area_type', 'casualty_imd_decile',\n",
      "       'vehicle_type', 'towing_and_articulation', 'vehicle_manoeuvre',\n",
      "       'vehicle_direction_from', 'vehicle_direction_to',\n",
      "       'vehicle_location_restricted_lane',\n",
      "       'vehicle_location_restricted_lane.1', 'skidding_and_overturning',\n",
      "       'hit_object_in_carriageway', 'vehicle_leaving_carriageway',\n",
      "       'hit_object_off_carriageway', 'first_point_of_impact',\n",
      "       'vehicle_left_hand_drive', 'journey_purpose_of_driver', 'sex_of_driver',\n",
      "       'age_of_driver', 'age_band_of_driver', 'engine_capacity_cc',\n",
      "       'propulsion_code', 'age_of_vehicle', 'driver_imd_decile',\n",
      "       'driver_home_area_type', 'lsoa_of_driver'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db761fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data = merged_data[merged_data != -1].dropna()\n",
    "# merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52dbb1",
   "metadata": {},
   "source": [
    "# Statistical information regarding traffic accident characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0f3ef",
   "metadata": {},
   "source": [
    "Now data is processed and ready to do analysis. The next we will performing the descriptive statestical summary of our dataset.In which we will get count of the traffic accident according to the casuality servity (fatal,serious,slight) with the considerdation of various variables such as day of week, light consition wheather condition etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6980d5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for day_of_week:\n",
      " Fatal:\n",
      "  Thursday: 714\n",
      "  Friday: 706\n",
      "  Sunday: 690\n",
      "  Saturday: 684\n",
      "  Wednesday: 682\n",
      "  Monday: 597\n",
      "  Tuesday: 594\n",
      " Serious:\n",
      "  Friday: 8648\n",
      "  Saturday: 8243\n",
      "  Wednesday: 7426\n",
      "  Monday: 7363\n",
      "  Thursday: 7202\n",
      "  Tuesday: 7197\n",
      "  Sunday: 6975\n",
      " Slight:\n",
      "  Friday: 31965\n",
      "  Thursday: 28226\n",
      "  Wednesday: 27683\n",
      "  Tuesday: 26970\n",
      "  Saturday: 26318\n",
      "  Monday: 25934\n",
      "  Sunday: 21454\n",
      "\n",
      "\n",
      "Analysis for road_type:\n",
      " Fatal:\n",
      "  Single carriageway: 3398\n",
      "  Dual carriageway: 1153\n",
      "  Roundabout: 51\n",
      "  Slip road: 37\n",
      "  Unknown: 18\n",
      "  One way street: 10\n",
      " Serious:\n",
      "  Single carriageway: 40043\n",
      "  Dual carriageway: 9128\n",
      "  Roundabout: 2079\n",
      "  Slip road: 733\n",
      "  One way street: 652\n",
      "  Unknown: 419\n",
      " Slight:\n",
      "  Single carriageway: 130070\n",
      "  Dual carriageway: 34242\n",
      "  Roundabout: 11561\n",
      "  Unknown: 4742\n",
      "  Slip road: 4140\n",
      "  One way street: 3795\n",
      "\n",
      "\n",
      "Analysis for light_conditions:\n",
      " Fatal:\n",
      "  Daylight: 2905\n",
      "  Darkness - lights lit: 831\n",
      "  Darkness - no lighting: 739\n",
      "  Darkness - lighting unknown: 111\n",
      "  Darkness - lights unlit: 72\n",
      "  Data missing or out of range: 9\n",
      " Serious:\n",
      "  Daylight: 37222\n",
      "  Darkness - lights lit: 10753\n",
      "  Darkness - no lighting: 3989\n",
      "  Darkness - lighting unknown: 687\n",
      "  Darkness - lights unlit: 401\n",
      "  Data missing or out of range: 2\n",
      " Slight:\n",
      "  Daylight: 140560\n",
      "  Darkness - lights lit: 35936\n",
      "  Darkness - no lighting: 7256\n",
      "  Darkness - lighting unknown: 3554\n",
      "  Darkness - lights unlit: 1220\n",
      "  Data missing or out of range: 24\n",
      "\n",
      "\n",
      "Analysis for weather_conditions:\n",
      " Fatal:\n",
      "  Fine no high winds: 3966\n",
      "  Raining no high winds: 458\n",
      "  Raining + high winds: 70\n",
      "  Fine + high winds: 49\n",
      "  Other: 48\n",
      "  Fog or mist: 31\n",
      "  Unknown: 25\n",
      "  Data missing or out of range: 13\n",
      "  Snowing no high winds: 7\n",
      " Serious:\n",
      "  Fine no high winds: 43895\n",
      "  Raining no high winds: 5532\n",
      "  Other: 1319\n",
      "  Raining + high winds: 641\n",
      "  Unknown: 581\n",
      "  Fine + high winds: 523\n",
      "  Snowing no high winds: 266\n",
      "  Fog or mist: 255\n",
      "  Snowing + high winds: 42\n",
      " Slight:\n",
      "  Fine no high winds: 152801\n",
      "  Raining no high winds: 19493\n",
      "  Other: 6012\n",
      "  Unknown: 4938\n",
      "  Raining + high winds: 1727\n",
      "  Fine + high winds: 1474\n",
      "  Snowing no high winds: 1170\n",
      "  Fog or mist: 690\n",
      "  Snowing + high winds: 218\n",
      "  Data missing or out of range: 27\n",
      "\n",
      "\n",
      "Analysis for road_surface_conditions:\n",
      " Fatal:\n",
      "  Dry: 3434\n",
      "  Wet or damp: 1176\n",
      "  Frost or ice: 22\n",
      "  Data missing or out of range: 21\n",
      "  Flood over 3cm. deep: 9\n",
      "  Snow: 5\n",
      " Serious:\n",
      "  Dry: 39178\n",
      "  Wet or damp: 12797\n",
      "  Frost or ice: 575\n",
      "  Snow: 204\n",
      "  unknown (self reported): 118\n",
      "  Data missing or out of range: 99\n",
      "  Flood over 3cm. deep: 83\n",
      " Slight:\n",
      "  Dry: 140956\n",
      "  Wet or damp: 41718\n",
      "  Frost or ice: 2043\n",
      "  unknown (self reported): 1865\n",
      "  Snow: 966\n",
      "  Data missing or out of range: 804\n",
      "  Flood over 3cm. deep: 198\n",
      "\n",
      "\n",
      "Analysis for sex_of_driver:\n",
      " Fatal:\n",
      "  Male: 3607\n",
      "  Female: 860\n",
      "  Not known: 200\n",
      " Serious:\n",
      "  Male: 36402\n",
      "  Female: 12558\n",
      "  Not known: 4093\n",
      "  Data missing or out of range: 1\n",
      " Slight:\n",
      "  Male: 115137\n",
      "  Female: 51405\n",
      "  Not known: 22007\n",
      "  Data missing or out of range: 1\n",
      "\n",
      "\n",
      "Analysis for casualty_class:\n",
      " Fatal:\n",
      "  Driver or rider: 3028\n",
      "  Passenger: 1138\n",
      "  Pedestrian: 501\n",
      " Serious:\n",
      "  Driver or rider: 36997\n",
      "  Passenger: 10724\n",
      "  Pedestrian: 5333\n",
      " Slight:\n",
      "  Driver or rider: 139406\n",
      "  Passenger: 36880\n",
      "  Pedestrian: 12264\n",
      "\n",
      "\n",
      "Analysis for junction_detail:\n",
      " Fatal:\n",
      "  Not at junction or within 20 metres: 3142\n",
      "  T or staggered junction: 733\n",
      "  Crossroads: 320\n",
      "  Other junction: 195\n",
      "  Private drive or entrance: 122\n",
      "  Roundabout: 95\n",
      "  Slip road: 30\n",
      "  More than 4 arms (not roundabout): 20\n",
      "  Mini-roundabout: 10\n",
      " Serious:\n",
      "  Not at junction or within 20 metres: 25441\n",
      "  T or staggered junction: 13742\n",
      "  Crossroads: 5070\n",
      "  Other junction: 3093\n",
      "  Roundabout: 2683\n",
      "  Private drive or entrance: 1107\n",
      "  More than 4 arms (not roundabout): 682\n",
      "  Mini-roundabout: 574\n",
      "  Slip road: 481\n",
      "  unknown (self reported): 181\n",
      " Slight:\n",
      "  Not at junction or within 20 metres: 75312\n",
      "  T or staggered junction: 51366\n",
      "  Crossroads: 19205\n",
      "  Roundabout: 15368\n",
      "  Other junction: 10520\n",
      "  Private drive or entrance: 4139\n",
      "  unknown (self reported): 3881\n",
      "  Slip road: 2991\n",
      "  More than 4 arms (not roundabout): 2978\n",
      "  Mini-roundabout: 2786\n",
      "  Data missing or out of range: 4\n",
      "\n",
      "\n",
      "Analysis for junction_control:\n",
      " Fatal:\n",
      "  Data missing or out of range: 3174\n",
      "  Give way or uncontrolled: 1208\n",
      "  Auto traffic signal: 279\n",
      "  Stop sign: 6\n",
      " Serious:\n",
      "  Data missing or out of range: 25651\n",
      "  Give way or uncontrolled: 22368\n",
      "  Auto traffic signal: 4360\n",
      "  Stop sign: 342\n",
      "  unknown (self reported): 179\n",
      "  Authorised person: 154\n",
      " Slight:\n",
      "  Give way or uncontrolled: 84138\n",
      "  Data missing or out of range: 76170\n",
      "  Auto traffic signal: 22829\n",
      "  unknown (self reported): 3503\n",
      "  Stop sign: 1218\n",
      "  Authorised person: 692\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load CSV files into Pandas DataFrames with low_memory=False\n",
    "labels_accident = \"https://raw.githubusercontent.com/Sayalinale/RoadTraffic-Analysis/main/Road-Safety-Open-Dataset-Data-Guide.csv\"\n",
    "df_accident_data_labels = pd.read_csv(labels_accident, low_memory=False)\n",
    "\n",
    "# Define a function to map codes to labels for a specific field\n",
    "def map_codes_to_labels(field_name):\n",
    "    field_labels = df_accident_data_labels[df_accident_data_labels['field name'] == field_name]\n",
    "    code_to_label = dict(zip(field_labels['code/format'], field_labels['label']))\n",
    "    return code_to_label\n",
    "\n",
    "# Define a function to count occurrences for a specific field by casualty_severity\n",
    "def count_field_by_severity(data, field_name):\n",
    "    counts = {}\n",
    "    for severity in [1, 2, 3]:\n",
    "        subset = data[data['accident_severity'] == severity]\n",
    "        field_counts = subset[field_name].value_counts()\n",
    "        counts[severity] = field_counts\n",
    "    return counts\n",
    "\n",
    "# List of variables which should analyze\n",
    "variables_to_analyze = [\n",
    "    'day_of_week',\n",
    "    'road_type',\n",
    "    'light_conditions',\n",
    "    'weather_conditions',\n",
    "    'road_surface_conditions',\n",
    "    'sex_of_driver',\n",
    "    'casualty_class',\n",
    "    'junction_detail',\n",
    "    'junction_control'\n",
    "]\n",
    "\n",
    "# Iterate over each variable and create tables\n",
    "for variable in variables_to_analyze:\n",
    "    # Count occurrences for the current variable by casualty_severity\n",
    "    variable_counts_by_severity = count_field_by_severity(merged_data, variable)\n",
    "\n",
    "    # Get the code to label mapping for the current variable\n",
    "    variable_labels = map_codes_to_labels(variable)\n",
    "\n",
    "    # Get the label for 'accident_severity' field\n",
    "    accident_severity_label = map_codes_to_labels('accident_severity')\n",
    "\n",
    "    # Display the counts with labels\n",
    "    print(f\"Analysis for {variable}:\")\n",
    "    for severity, counts in variable_counts_by_severity.items():\n",
    "        severity_label = accident_severity_label.get(str(severity), 'Unknown')\n",
    "        print(f\" {severity_label}:\")\n",
    "        for code, count in counts.items():\n",
    "            label = variable_labels.get(str(code), 'Unknown')\n",
    "            print(f\"  {label}: {count}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e1c18cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident_severity: 1.0\n",
      "casualty_severity: 0.8427407000572424\n",
      "did_police_officer_attend_scene_of_accident: 0.1688781437143721\n",
      "hit_object_in_carriageway: 0.10847302170061227\n",
      "vehicle_location_restricted_lane: 0.10845346572841447\n",
      "vehicle_location_restricted_lane.1: 0.10845346572841415\n",
      "hit_object_off_carriageway: 0.1039373035463503\n",
      "vehicle_left_hand_drive: 0.09990976872222491\n",
      "junction_control: 0.09028142063434047\n",
      "trunk_road_flag.1: 0.08679564487469517\n",
      "trunk_road_flag: 0.08679564487469434\n",
      "vehicle_manoeuvre: 0.08144323856635824\n",
      "sex_of_driver: 0.08119273931047775\n",
      "skidding_and_overturning: 0.07621814254790718\n",
      "first_point_of_impact: 0.07604097849714683\n",
      "pedestrian_crossing_physical_facilities: 0.07601843984877772\n",
      "pedestrian_crossing_human_control: 0.07472257471703823\n",
      "second_road_class: 0.07441180273309352\n",
      "longitude: 0.0691579465471388\n",
      "location_easting_osgr: 0.06812464801883984\n",
      "junction_detail: 0.06567298047658213\n",
      "vehicle_leaving_carriageway: 0.04529232568389992\n",
      "sex_of_casualty: 0.04487190949919495\n",
      "vehicle_direction_to: 0.04364884752120011\n",
      "special_conditions_at_site: 0.040824848990394756\n",
      "weather_conditions: 0.04038268290355677\n",
      "towing_and_articulation: 0.038486360152627935\n",
      "vehicle_direction_from: 0.03797049842035064\n",
      "carriageway_hazards: 0.03470500076248059\n",
      "propulsion_code: 0.02601239483712973\n",
      "first_road_class: 0.023788697161227328\n",
      "second_road_number: 0.020736659101632235\n",
      "road_surface_conditions: 0.019793721718723158\n",
      "journey_purpose_of_driver: 0.013460417156773399\n",
      "vehicle_reference_x: 0.01032816084143711\n",
      "day_of_week: 0.007601762197427291\n",
      "bus_or_coach_passenger: 0.006671303725883541\n",
      "local_authority_district: -0.0011600999188846179\n",
      "age_of_vehicle: -0.0014697956005514353\n",
      "car_passenger: -0.0033888170398433115\n",
      "casualty_type: -0.004623188321101212\n",
      "pedestrian_road_maintenance_worker: -0.009002232713542222\n",
      "vehicle_type: -0.009526629774312085\n",
      "first_road_number: -0.012108580779540613\n",
      "casualty_imd_decile: -0.012929970114515727\n",
      "engine_capacity_cc: -0.017038637293655512\n",
      "casualty_home_area_type: -0.020634758217978378\n",
      "road_type: -0.02414816965509217\n",
      "number_of_vehicles: -0.02995949731843738\n",
      "driver_imd_decile: -0.04384354928921301\n",
      "pedestrian_movement: -0.04421209458667551\n",
      "pedestrian_location: -0.05312396352516576\n",
      "casualty_class: -0.05794730255327371\n",
      "age_band_of_casualty: -0.06150927749805412\n",
      "driver_home_area_type: -0.06368309407920095\n",
      "light_conditions: -0.06414636115807296\n",
      "age_of_casualty: -0.06712075718837443\n",
      "age_of_driver: -0.07642381185744994\n",
      "age_band_of_driver: -0.07839906086333216\n",
      "latitude: -0.092916163430574\n",
      "location_northing_osgr: -0.09308675451101552\n",
      "police_force: -0.09821937380798358\n",
      "casualty_reference: -0.11509473831823414\n",
      "urban_or_rural_area: -0.13842577943521645\n",
      "speed_limit: -0.14307941016632372\n",
      "number_of_casualties: -0.15744952699165995\n",
      "accident_year: nan\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation matrix\n",
    "corr_matrix = merged_data.corr()\n",
    "\n",
    "# Calculate the correlation between features and the target variable\n",
    "corr_with_target = merged_data.corr()['accident_severity'].sort_values(ascending=False)\n",
    "\n",
    "# Print the correlation values with the target variable one by one\n",
    "for feature, correlation in corr_with_target.items():\n",
    "    print(f\"{feature}: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c05abb",
   "metadata": {},
   "source": [
    "Here we can see the correlation values between the features and the target variable \"accident_severity.\" Based on these correlation values, we can see how each feature is related to the severity of accidents. Here are some key takeaways:\n",
    "\n",
    "Positive Correlations (values closer to 1):\n",
    "- Features like \"casualty_severity,\" \"did_police_officer_attend_scene_of_accident,\" and \"hit_object_in_carriageway\" have positive correlations with accident severity. This means that as these features increase, the accident severity tends to increase as well.\n",
    "\n",
    "Negative Correlations (values closer to -1):\n",
    "- Features like \"speed_limit,\" \"number_of_casualties,\" \"urban_or_rural_area,\" and others have negative correlations with accident severity. This implies that lower speed limits, fewer casualties, and accidents in urban areas are associated with less severe accidents.\n",
    "\n",
    "Correlations close to zero indicate weaker relationships between the features and accident severity.\n",
    "\n",
    "It's essential to interpret these correlations in the context of our analysis goals. Features with strong positive or negative correlations can be considered important factors affecting accident severity and may be valuable for building predictive models or further analysis.\n",
    "\n",
    "These relationships are based on statistical associations, and further analysis or domain knowledge may be needed to understand the underlying causes of these correlations.\n",
    "\n",
    "Additionally, we've noted that the \"accident_year\" feature has a correlation value of \"NaN.\" This might be due to limited variation in the \"accident_year\" feature, making it uninformative for predicting accident severity. We may consider excluding it from our analysis if it does not provide meaningful information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f4d022",
   "metadata": {},
   "source": [
    "# Decesion Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd389e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.94\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.63      0.77       947\n",
      "           2       0.98      0.77      0.87     10585\n",
      "           3       0.94      1.00      0.97     37723\n",
      "\n",
      "    accuracy                           0.94     49255\n",
      "   macro avg       0.97      0.80      0.87     49255\n",
      "weighted avg       0.95      0.94      0.94     49255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select features and target variable\n",
    "X = merged_data[['casualty_severity']]  # Features\n",
    "y = merged_data['accident_severity']    # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Decision Tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = clf.predict(X_test) \n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Print accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Temporarily suppress the UndefinedMetricWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "    \n",
    "    # Generate a classification report with zero_division parameter\n",
    "    class_report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Restore warning settings to their original state\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d506c3a",
   "metadata": {},
   "source": [
    "# Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db01632",
   "metadata": {},
   "source": [
    "After obtaining the relevant feature by using the corelation between the target variable and feature implemented the logistic regression algorithm on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05498a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9441884072682977\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.63      0.77       947\n",
      "           2       0.98      0.77      0.87     10585\n",
      "           3       0.94      1.00      0.97     37723\n",
      "\n",
      "    accuracy                           0.94     49255\n",
      "   macro avg       0.97      0.80      0.87     49255\n",
      "weighted avg       0.95      0.94      0.94     49255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X = merged_data[['casualty_severity']]\n",
    "y = merged_data['accident_severity']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f2cdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7658714851284134\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       947\n",
      "           2       0.00      0.00      0.00     10585\n",
      "           3       0.77      1.00      0.87     37723\n",
      "\n",
      "    accuracy                           0.77     49255\n",
      "   macro avg       0.26      0.33      0.29     49255\n",
      "weighted avg       0.59      0.77      0.66     49255\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into features (X) and the target variable (y)\n",
    "X = merged_data[['casualty_class']]\n",
    "y = merged_data['accident_severity']\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and train a Support Vector Machine (SVM) model\n",
    "model = SVC(kernel='linear') \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Suppress the UndefinedMetricWarning\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    \n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76bb8cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7658714851284134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       947\n",
      "           2       0.00      0.00      0.00     10585\n",
      "           3       0.77      1.00      0.87     37723\n",
      "\n",
      "    accuracy                           0.77     49255\n",
      "   macro avg       0.26      0.33      0.29     49255\n",
      "weighted avg       0.59      0.77      0.66     49255\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayali\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sayali\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\sayali\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Split data into train and test sets\n",
    "X = merged_data[['weather_conditions']]  # Feature\n",
    "y = merged_data['accident_severity']  # Target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)  \n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623aed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
